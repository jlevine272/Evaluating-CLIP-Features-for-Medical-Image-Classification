{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "import wandb\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoshl\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_dataset, LESION_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# CLIP Zero-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HAM10000 dataset...\n",
      "Train size: 9013\n",
      "Test size: 1002\n",
      "<torch.utils.data.dataset.Subset object at 0x00000290AD37F910>\n",
      "<torch.utils.data.dataset.Subset object at 0x00000290AD37F5E0>\n"
     ]
    }
   ],
   "source": [
    "ham_train, ham_test = load_dataset(\"HAM10000\", transform=clip_preprocess)\n",
    "\n",
    "print(f\"Train size: {len(ham_train)}\")\n",
    "print(f\"Test size: {len(ham_test)}\")\n",
    "print(ham_train)\n",
    "print(ham_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clip_zero_shot(data_set, classes):\n",
    "    # https://colab.research.google.com/drive/1IqJfogZdC61dgE4BDQILCJS-zUiphD4y?authuser=2#scrollTo=EuZFg3ZlHOVD\n",
    "    data_loader = DataLoader(data_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    # Encode text features here\n",
    "    text_inputs = torch.cat([clip.tokenize(f\"a photo of a {c}, a type of skin lesion.\") for c in classes]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    # Encode image features here\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for image, label in tqdm(data_loader):\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = clip_model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "        _, pred = similarity.max(dim=-1)\n",
    "        correct += (pred == label).sum().item()\n",
    "        total += len(label)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lesion_classes = LESION_TYPE.values() # This was probably only because the class labels were numbers, not strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a660ca99614060833156fbecb63340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 21.136%\n"
     ]
    }
   ],
   "source": [
    "accuracy = clip_zero_shot(data_set=ham_train, classes=lesion_classes)\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# CLIP Linear-Probe Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_set):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(data_set, batch_size=BATCH_SIZE)):\n",
    "            features = clip_model.encode_image(images.to(device))\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1da3a27e6e74481aa291c1fd517c0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096c522605614f7d87fac8f3937abfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(ham_train)\n",
    "test_features, test_labels = get_features(ham_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 81.238%\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression\n",
    "classifier = LogisticRegression(random_state=0, C=0.316, max_iter=10000, verbose=1, n_jobs=-1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(float))\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]\n",
      "Accuracy = 72.854%\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression\n",
    "classifier = svm.SVC(random_state=0, C=0.316, max_iter=5000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(float))\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# K-Means Clusteriungfrom scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x_train, y_train, x_test, y_test, K=5):\n",
    "    # Needs code here\n",
    "    test_pred = []\n",
    "    for i in tqdm(range(len(x_test))):\n",
    "        distance = np.linalg.norm(x_train - x_test[i], axis=-1)\n",
    "        indices = np.argsort(distance)[:K]\n",
    "        neighbors_labels = y_train[indices]\n",
    "        test_pred.append(stats.mode(neighbors_labels).mode[0])\n",
    "\n",
    "    correct = (test_pred == y_test).sum()\n",
    "    total = len(y_test)\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95de84b62b9d4c969e10cb2085bb53d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1002 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_19532\\3497779333.py:8: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  test_pred.append(stats.mode(neighbors_labels).mode[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 73.453%\n"
     ]
    }
   ],
   "source": [
    "accuracy = knn(train_features, train_labels, test_features, test_labels, K=1)\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 21.856%\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression\n",
    "classifier = KMeans(n_clusters=7)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(float))\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 73.353%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=24)]: Using backend ThreadingBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=24)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression\n",
    "classifier = RandomForestClassifier(random_state=0, verbose=1, n_jobs=-1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(float))\n",
    "print(f\"\\nAccuracy = {100*accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_preprocess = models.ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
    "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "resnet50 = models.resnet50(weights=weights)\n",
    "\n",
    "# Change last layer\n",
    "num_features = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_features, len(LESION_TYPE))\n",
    "\n",
    "resnet50.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HAM10000 dataset...\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_dataset(\"HAM10000\", transform=resnet_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        num_correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", position=2, leave=False):\n",
    "            num_correct += torch.sum(labels.to(device) == torch.argmax(model(images.to(device)), 1)).item()\n",
    "            total += labels.size(0)\n",
    "        return num_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, loss_fn, train_data, test_data, config):\n",
    "    \"\"\"\n",
    "    Train a PyTorch model using the provided parameters.\n",
    "\n",
    "    :param model: PyTorch model to train\n",
    "    :param optim: Optimizer to use for training\n",
    "    :param loss_fn: Loss function to use for training\n",
    "    :param train_data: Training dataset\n",
    "    :param test_data: Test dataset\n",
    "    :param num_epochs: Number of epochs to train for (default is 100)\n",
    "    :param batch_size: Batch size to use for data loading (default is 32)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"vision-project-resnet\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config=config)\n",
    "    \n",
    "    num_epochs = config['epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\", position=0, leave=True):\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, targets in tqdm(train_loader, desc=\"Training\", position=1, leave=False):\n",
    "            # Forward pass\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # Calculate train loss\n",
    "            train_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs, 1)\n",
    "            total_train += targets.size(0)\n",
    "            correct_train += (predicted == targets).sum().item()\n",
    "\n",
    "        if (epoch+1) % 2 == 0 or epoch == num_epochs - 1:\n",
    "            train_loss /= len(train_loader)\n",
    "            train_accuracy = correct_train / total_train\n",
    "\n",
    "            test_accuracy = evaluate(model, test_loader)\n",
    "            model.train()\n",
    "\n",
    "            # , Test Loss: {test_loss:.4f}\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Log metrics to wandb\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"test_accuracy\": test_accuracy\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\":1e-4,\n",
    "    \"batch_size\":64,\n",
    "    \"epochs\":30,\n",
    "    \"weight_decay\":1e-5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=config['batch_size'], shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05292061907139291\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(resnet50, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuned Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(resnet50.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet50, optim, loss, train_data, test_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
